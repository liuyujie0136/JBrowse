{"version":3,"file":"static/js/4061.70b9f765.chunk.js","mappings":"sGAAA,IAAIA,EAA+B,EAAQ,OAqB3CC,EAAOC,QAnBP,SAAkCC,EAAQC,GACxC,GAAc,MAAVD,EAAgB,MAAO,GAC3B,IACIE,EAAKC,EADLC,EAASP,EAA6BG,EAAQC,GAGlD,GAAII,OAAOC,sBAAuB,CAChC,IAAIC,EAAmBF,OAAOC,sBAAsBN,GAEpD,IAAKG,EAAI,EAAGA,EAAII,EAAiBC,OAAQL,IACvCD,EAAMK,EAAiBJ,GACnBF,EAASQ,QAAQP,IAAQ,GACxBG,OAAOK,UAAUC,qBAAqBC,KAAKZ,EAAQE,KACxDE,EAAOF,GAAOF,EAAOE,IAIzB,OAAOE,GAGkCN,EAAOC,QAAQc,YAAa,EAAMf,EAAOC,QAAiB,QAAID,EAAOC,S,kBCNhHD,EAAOC,QAfP,SAAuCC,EAAQC,GAC7C,GAAc,MAAVD,EAAgB,MAAO,GAC3B,IAEIE,EAAKC,EAFLC,EAAS,GACTU,EAAaT,OAAOU,KAAKf,GAG7B,IAAKG,EAAI,EAAGA,EAAIW,EAAWN,OAAQL,IACjCD,EAAMY,EAAWX,GACbF,EAASQ,QAAQP,IAAQ,IAC7BE,EAAOF,GAAOF,EAAOE,IAGvB,OAAOE,GAGuCN,EAAOC,QAAQc,YAAa,EAAMf,EAAOC,QAAiB,QAAID,EAAOC,S,6ECdrHM,OAAOW,eAAejB,EAAS,aAAc,CAAEkB,OAAO,I,IAEhDC,EAAAA,WAOF,WAAYC,EAAMC,EAAMC,GAA8B,IAAzBC,EAAyB,4DAAXC,EAAW,UAClDC,KAAKL,KAAOA,EACZK,KAAKJ,KAAOA,EACZI,KAAKH,IAAMA,EACXG,KAAKC,aAAeH,E,wCAExB,WACI,gBAAUE,KAAKL,KAAf,aAAwBK,KAAKJ,KAA7B,iBAA0CI,KAAKH,IAA/C,yBAAmEG,KAAKF,cAAxE,O,sBAEJ,WACI,OAAOE,KAAKE,mB,uBAEhB,SAAUC,GACN,OAAQH,KAAKL,KAAKS,UAAUD,EAAER,OAC1BK,KAAKJ,KAAKQ,UAAUD,EAAEP,OACtBI,KAAKH,IAAMM,EAAEN,M,yBAErB,WACI,YAA0BE,IAAtBC,KAAKC,aACED,KAAKC,aAETD,KAAKJ,KAAKS,cAAV,MAAsCL,KAAKL,KAAKU,kB,EA5BzDX,GA+BNnB,EAAAA,QAAkBmB,G,0MCjCdY,EAAmBN,MAAQA,KAAKM,kBAAqBzB,OAAO0B,OAAU,SAASC,EAAGC,EAAGC,EAAGC,QAC7EZ,IAAPY,IAAkBA,EAAKD,GAC3B7B,OAAOW,eAAegB,EAAGG,EAAI,CAAEC,YAAY,EAAMC,IAAK,WAAa,OAAOJ,EAAEC,OAC1E,SAASF,EAAGC,EAAGC,EAAGC,QACTZ,IAAPY,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,KAEVI,EAAsBd,MAAQA,KAAKc,qBAAwBjC,OAAO0B,OAAU,SAASC,EAAGO,GACxFlC,OAAOW,eAAegB,EAAG,UAAW,CAAEI,YAAY,EAAMnB,MAAOsB,KAC9D,SAASP,EAAGO,GACbP,EAAC,QAAcO,IAEfC,EAAgBhB,MAAQA,KAAKgB,cAAiB,SAAUC,GACxD,GAAIA,GAAOA,EAAI5B,WAAY,OAAO4B,EAClC,IAAIC,EAAS,GACb,GAAW,MAAPD,EAAa,IAAK,IAAIP,KAAKO,EAAe,YAANP,GAAmB7B,OAAOK,UAAUiC,eAAe/B,KAAK6B,EAAKP,IAAIJ,EAAgBY,EAAQD,EAAKP,GAEtI,OADAI,EAAmBI,EAAQD,GACpBC,GAEPE,EAAmBpB,MAAQA,KAAKoB,iBAAoB,SAAUH,GAC9D,OAAQA,GAAOA,EAAI5B,WAAc4B,EAAM,CAAE,QAAWA,IAExDpC,OAAOW,eAAejB,EAAS,aAAc,CAAEkB,OAAO,IACtD,IAAM4B,EAASD,EAAgBE,EAAQ,QACjCC,EAAoBD,EAAQ,OAC5BE,EAAkBR,EAAaM,EAAQ,QACvCG,EAAUL,EAAgBE,EAAQ,QAClCI,EAASJ,EAAQ,MACjBK,EAAcP,EAAgBE,EAAQ,QACtCM,EAAa,SACbC,EAAa,SAInB,SAASC,EAAOC,EAAKC,GACjB,OAAOC,KAAKC,MAAMH,EAAM,KAAH,IAAG,EAAKC,I,IAE3BG,EAAAA,SAAAA,G,kBACF,WAAYC,GAAM,wBACd,cAAMA,IACDC,aAAe,EACpB,EAAKC,MAAQ,EACb,EAAKC,SAAW,EAJF,E,8DAMlB,WAAgBC,GAAhB,8FAAyBC,EAAzB,+BAAgC,GAAhC,SAC4BzC,KAAK0C,MAAMD,GADvC,UACUE,EADV,iDAGgB,GAHhB,UAKUC,EAAQD,EAAUE,YAAYL,GACxBG,EAAUG,QAAQF,GANlC,2CAQgB,GARhB,aAUYG,EAAUJ,EAAUG,QAAQF,GAA5BG,OAVZ,0CAYeA,EAAMC,WAZrB,kCAcY,GAdZ,iD,wGAgBA,kFACU,IAAIC,MAAM,uCADpB,2C,gFAIA,SAAaC,EAAOC,EAAQC,GACxB,GAAIA,EAAY,GACZ,MAAO,CACHC,YAAa,GACbR,YAAa,IAGrB,IAAMS,EAAcJ,EAAMK,YAAYJ,GAChCK,EAA+B,MAAdF,EAAwB,uBAAyB,iBAClEG,EAAS,CAAE,EAAG,UAAW,EAAG,MAAO,EAAG,OAAsB,GAAdH,GACpD,IAAKG,EACD,MAAM,IAAIR,MAAJ,4CAA+CK,IAEzD,IAAMI,EAAgB,CAClBC,IAAKT,EAAMK,YAAYJ,EAAS,GAChCS,MAAOV,EAAMK,YAAYJ,EAAS,GAClCU,IAAKX,EAAMK,YAAYJ,EAAS,KAE9BW,EAAYZ,EAAMK,YAAYJ,EAAS,IACvCY,EAAWD,EAAYE,OAAOC,aAAaH,GAAa,GACxDI,EAAYhB,EAAMK,YAAYJ,EAAS,IACvCgB,EAAoBjB,EAAMK,YAAYJ,EAAS,IACrD,EAAqCnD,KAAKoE,gBAAgBlB,EAAMmB,MAAMlB,EAAS,GAAIA,EAAS,GAAKgB,IACjG,MAAO,CACHd,YAFJ,EAAQA,YAGJR,YAHJ,EAAqBA,YAIjBqB,UAAAA,EACAH,SAAAA,EACAL,cAAAA,EACAD,OAAAA,EACAD,eAAAA,K,6BAGR,SAAgBc,GAKZ,IAJA,IAAIC,EAAY,EACZC,EAAgB,EACdnB,EAAc,GACdR,EAAc,GACXlE,EAAI,EAAGA,EAAI2F,EAAWtF,OAAQL,GAAK,EACxC,IAAK2F,EAAW3F,GAAI,CAChB,GAAI6F,EAAgB7F,EAAG,CACnB,IAAI6D,EAAU8B,EAAWG,SAAS,OAAQD,EAAe7F,GACzD6D,EAAUxC,KAAK0E,aAAalC,GAC5Ba,EAAYkB,GAAa/B,EACzBK,EAAYL,GAAW+B,EAE3BC,EAAgB7F,EAAI,EACpB4F,GAAa,EAGrB,MAAO,CAAE1B,YAAAA,EAAaQ,YAAAA,K,+CAG1B,8HAAaZ,EAAb,+BAAoB,GAApB,KAC4BlB,EAAkBoD,MAD9C,SAC4D3E,KAAK4E,WAAWC,SAASpC,GADrF,6DACUS,EADV,QAIc4B,aAAa,KAAOlD,EAJlC,iBAKQmD,EAAa,EALrB,2BAOa7B,EAAM4B,aAAa,KAAOjD,EAPvC,iBAQQkD,EAAa,EARrB,8BAWc,IAAI9B,MAAM,kBAXxB,eAcIjD,KAAKuC,SAAWW,EAAMK,YAAY,GAClCvD,KAAKsC,MAAQY,EAAMK,YAAY,GAC/BvD,KAAKqC,eAAiB,GAAyB,GAAlBrC,KAAKsC,MAAQ,IAAW,GAAK,EACpD0C,EAjBV,SAiByB,EAAMhF,KAAKuC,SAAwB,EAAbvC,KAAKsC,OAC1Cc,EAAYF,EAAMK,YAAY,IAChC0B,EAAM,CACN5B,YAAa,GACbR,YAAa,IAEbO,IACA6B,EAAMjF,KAAKkF,aAAahC,EAAO,GAAIE,IAEjC+B,EAAWjC,EAAMK,YAAY,GAAKH,GAGpCgC,EAAa,GAAKhC,EAAY,EAC5BN,EAAU,IAAIuC,MAAMF,GAAUG,KAAK,GAAGC,KAAI,WAE5C,IAAMC,EAAWtC,EAAMK,YAAY6B,GACnCA,GAAc,EAGd,IAFA,IACIrC,EADE0C,EAAW,GAERC,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAAG,CAClC,IAAM7F,EAAMqD,EAAM4B,aAAaM,GAC/B,GAAIvF,EAAM,EAAKwC,aAGXU,EAAQ,EAAK4C,eAAezC,EAAOkC,EAAa,GAChDA,GAAc,OAEb,CACD,IAAMQ,GAAU,EAAIpE,EAAgBqE,WAAW3C,EAAOkC,EAAa,GACnEU,EAAgB,EAAKC,eAAeD,EAAeF,GACnD,IAAMI,EAAa9C,EAAMK,YAAY6B,EAAa,IAClDA,GAAc,GAEd,IADA,IAAMa,EAAS,IAAIZ,MAAMW,GAChBtF,EAAI,EAAGA,EAAIsF,EAAYtF,GAAK,EAAG,CACpC,IAAMwF,GAAI,EAAI1E,EAAgBqE,WAAW3C,EAAOkC,GAC1CrE,GAAI,EAAIS,EAAgBqE,WAAW3C,EAAOkC,EAAa,GAC7DA,GAAc,GAEda,EAAOvF,GAAK,IAAIe,EAAQ0E,QAAQD,EAAGnF,EAAGlB,GAE1C4F,EAAS5F,GAAOoG,GAGxB,MAAO,CAAER,SAAAA,EAAU1C,MAAAA,MA5D3B,yBA+DWkC,GA/DX,IAgEQmB,KAAK,EACLjB,SAAAA,EACAkB,aAAc,MACdP,cAAAA,EACAf,WAAAA,EACAjC,QAAAA,EACAR,MAAOtC,KAAKsC,MACZD,aAAcrC,KAAKqC,aACnB2C,aAAAA,KAxER,iD,kFA2EA,SAAe9B,EAAOC,GAElB,MAAO,CAAEH,WADS,EAAItB,EAAO4E,cAAcjF,EAAO8E,QAAQI,YAAYlB,MAAMnG,UAAUmF,MAAMjF,KAAK8D,EAAOC,EAAS,GAAIA,EAAS,KAAK,O,uDAGvI,WAAqBX,EAASgE,EAAKC,GAAnC,kHAAwChE,EAAxC,+BAA+C,GACvC+D,EAAM,IACNA,EAAM,GAFd,SAI4BxG,KAAK0C,MAAMD,GAJvC,UAIUE,EAJV,gDAMe,IANf,UAQUC,EAAQD,EAAUE,YAAYL,GAC9BkE,EAAK/D,EAAUG,QAAQF,GATjC,0CAWe,IAXf,QAcU+D,EAAkB3G,KAAK4G,SAASJ,EAAKC,GACrCR,EAAS,GAfnB,IAiB+BU,GAjB/B,IAiBI,2BACI,IADwC,eAAhC/C,EAAgC,KAAzBC,EAAyB,KAC/BhE,EAAM+D,EAAO/D,GAAOgE,EAAKhE,IAC9B,GAAI6G,EAAGjB,SAAS5F,GAEZ,IADMgH,EAAYH,EAAGjB,SAAS5F,GACrBiH,EAAI,EAAGA,EAAID,EAAU7H,SAAU8H,EACpCb,EAAOc,KAAK,IAAItF,EAAQ0E,QAAQU,EAAUC,GAAGnH,KAAMkH,EAAUC,GAAGlH,KAAMC,IAtB1F,wDA2BW,EAAI6B,EAAOsF,gBAAgBf,EAAQ,IAAIzE,EAAgB2E,QAAQ,EAAG,KA3B7E,iD,iFAgCA,SAASc,EAAKpD,IACVoD,GAAO,GACG,IACNA,EAAM,GAENpD,EAAM,KAAH,IAAG,EAAK,MACXA,EAAM,KAAH,IAAG,EAAK,KAEfA,GAAO,EAKP,IAJA,IA9Ma7B,EA8MTkF,EAAI,EACJC,EAAI,EACJC,EAAIpH,KAAKuC,SAAwB,EAAbvC,KAAKsC,MACvB+E,EAAO,GACNH,GAAKlH,KAAKsC,MAAO8E,GAAK,EAAGD,IAlNnBnF,EAkNsC,EAAJkF,EAAH,EAjNnC,KAAH,IAAG,EAAKlF,IAiNyCkF,GAAK,EAAG,CAC3D,IAAM/G,EAAIgH,EAAIrF,EAAOmF,EAAKG,GACpBE,EAAIH,EAAIrF,EAAO+B,EAAKuD,GAC1B,GAAIE,EAAInH,EAAIkH,EAAKrI,OAASgB,KAAKqC,aAC3B,MAAM,IAAIY,MAAJ,gBAAmBgE,EAAnB,YAA0BpD,EAA1B,2DAAgF7D,KAAKuC,SAArF,mBAAwGvC,KAAKsC,MAA7G,6DAEV+E,EAAKN,KAAK,CAAC5G,EAAGmH,IAElB,OAAOD,M,EApNTlF,CAAYR,EAAYwE,SAuN9B5H,EAAAA,QAAkB4D,G,mCC5PlB,IAAIf,EAAmBpB,MAAQA,KAAKoB,iBAAoB,SAAUH,GAC9D,OAAQA,GAAOA,EAAI5B,WAAc4B,EAAM,CAAE,QAAWA,IAExDpC,OAAOW,eAAejB,EAAS,aAAc,CAAEkB,OAAO,IACtDlB,EAAQ4D,IAAM5D,EAAQgJ,IAAMhJ,EAAQiJ,sBAAmB,EACvD,IAAMC,EAAqBrG,EAAgBE,EAAQ,QACnD/C,EAAQiJ,iBAAmBC,EAAmBtB,QAC9C,IAAMuB,EAAQtG,EAAgBE,EAAQ,QACtC/C,EAAQgJ,IAAMG,EAAMvB,QACpB,IAAMwB,EAAQvG,EAAgBE,EAAQ,QACtC/C,EAAQ4D,IAAMwF,EAAMxB,S,4ICVhB/E,EAAmBpB,MAAQA,KAAKoB,iBAAoB,SAAUH,GAC9D,OAAQA,GAAOA,EAAI5B,WAAc4B,EAAM,CAAE,QAAWA,IAExDpC,OAAOW,eAAejB,EAAS,aAAc,CAAEkB,OAAO,IACtD,IAAMmI,EAA4BxG,EAAgBE,EAAQ,QACpDuG,EAAczG,EAAgBE,EAAQ,QACtCwG,EAAAA,WAKF,cAAuD,IAAzClD,EAAyC,EAAzCA,WAAyC,IAA7BmD,cAAAA,OAA6B,MAAb,SAACC,GAAD,OAAOA,GAAM,YACnDhI,KAAK4E,WAAaA,EAClB5E,KAAK0E,aAAeqD,E,gEAExB,yGAAkBtF,EAAlB,+BAAyB,GAAzB,SAEuCzC,KAAK0C,MAAMD,GAFlD,yBAEYK,QAAYmF,EAFxB,yBAGWA,GAHX,gD,kFAKA,SAAeC,EAAYC,GACvB,OAAID,EACOA,EAAW9H,UAAU+H,GAAiB,EACvCA,EACAD,EAGCC,I,8CAGf,4GAAY1F,EAAZ,+BAAmB,GACVzC,KAAKoI,cACNpI,KAAKoI,YAAc,IAAIR,EAA0BzB,QAAQ,CACrDkC,MAAO,IAAIR,EAAY1B,QAAQ,CAAEmC,QAAS,IAC1ChD,KAAM,kBAAM,EAAKiD,OAAO9F,OAJpC,kBAOWzC,KAAKoI,YAAYvH,IAAI,QAAS,UAAMd,IAP/C,gD,wGASA,WAAgByI,GAAhB,wFAAuB/F,EAAvB,+BAA8B,GAA9B,SACqBzC,KAAK0C,MAAMD,GADhC,eAC+C+F,EAD/C,YACuC1F,QADvC,gCACyD,GADzD,uCAC6D2C,UAD7D,gD,2DAjCEqC,GAqCNvJ,EAAAA,QAAkBuJ,G,6HC3Cd1G,EAAmBpB,MAAQA,KAAKoB,iBAAoB,SAAUH,GAC9D,OAAQA,GAAOA,EAAI5B,WAAc4B,EAAM,CAAE,QAAWA,IAExDpC,OAAOW,eAAejB,EAAS,aAAc,CAAEkB,OAAO,IACtD,IAAMmI,EAA4BxG,EAAgBE,EAAQ,QACpDuG,EAAczG,EAAgBE,EAAQ,QACtCmH,EAAuBnH,EAAQ,MAC/BC,EAAoBD,EAAQ,OAC5BI,EAASJ,EAAQ,MACjBoG,EAAQtG,EAAgBE,EAAQ,QAChCqG,EAAQvG,EAAgBE,EAAQ,QACtC,SAASoH,EAAQC,GACb,OAAO,IAAIC,SAAQ,SAAAC,GACfC,WAAWD,EAASF,M,IAGtBnB,EAAAA,WAgBF,cAAoK,IAAtJuB,EAAsJ,EAAtJA,KAAMnE,EAAgJ,EAAhJA,WAAYoE,EAAoI,EAApIA,QAASC,EAA2H,EAA3HA,cAAeC,EAA4G,EAA5GA,QAASC,EAAmG,EAAnGA,cAAmG,IAApFC,eAAAA,OAAoF,MAAnE,IAAmE,MAAzDrB,cAAAA,OAAyD,MAAzC,SAAAC,GAAC,OAAIA,GAAoC,MAAjCqB,eAAAA,OAAiC,MAAhB,EAAI,KAAJ,IAAI,EAAK,IAAO,EAChK,GADgK,UAC5JzE,EACA5E,KAAK4E,WAAaA,MAEjB,KAAImE,EAIL,MAAM,IAAIO,UAAU,0CAHpBtJ,KAAK4E,WAAa,IAAI6D,EAAqBc,UAAUR,GAKzD,GAAIE,EACAjJ,KAAKwJ,MAAQ,IAAI9B,EAAMvB,QAAQ,CAC3BvB,WAAYqE,EACZlB,cAAAA,SAGH,GAAIoB,EACLnJ,KAAKwJ,MAAQ,IAAI7B,EAAMxB,QAAQ,CAC3BvB,WAAYuE,EACZpB,cAAAA,SAGH,GAAIiB,EACLhJ,KAAKwJ,MAAQ,IAAI9B,EAAMvB,QAAQ,CAC3BvB,WAAY,IAAI6D,EAAqBc,UAAUP,GAC/CjB,cAAAA,SAGH,GAAImB,EACLlJ,KAAKwJ,MAAQ,IAAI7B,EAAMxB,QAAQ,CAC3BvB,WAAY,IAAI6D,EAAqBc,UAAUL,GAC/CnB,cAAAA,QAGH,KAAIgB,EAOL,MAAM,IAAIO,UAAU,yEANpBtJ,KAAKwJ,MAAQ,IAAI9B,EAAMvB,QAAQ,CAC3BvB,WAAY,IAAI6D,EAAqBc,UAAzB,UAAsCR,EAAtC,SACZhB,cAAAA,IAMR/H,KAAKoJ,eAAiBA,EACtBpJ,KAAK0E,aAAeqD,EACpB/H,KAAKyJ,WAAa,IAAI7B,EAA0BzB,QAAQ,CACpDkC,MAAO,IAAIR,EAAY1B,QAAQ,CAC3BmC,QAASrG,KAAKC,MAAMmH,EAAiB,SAEzC/D,KAAMtF,KAAK0J,UAAUC,KAAK3J,Q,6DAUlC,WAAewC,EAASoB,EAAOC,EAAKpB,GAApC,oHAEQmH,EAAU,GAEM,qBAATnH,EAJf,sBAKc,IAAI6G,UAAU,kCAL5B,UAOwB,oBAAT7G,EACPoH,EAAWpH,GAGXmH,EAAUnH,EACVoH,EAAWpH,EAAKqH,mBAEJ/J,IAAZyC,EAdR,sBAec,IAAI8G,UAAU,0CAf5B,UAiBSO,EAjBT,sBAkBc,IAAIP,UAAU,kCAlB5B,wBAoB2BtJ,KAAKwJ,MAAMO,YAAYH,GApBlD,WAoBUI,EApBV,QAqBI,EAAItI,EAAOuI,kBAAkBC,GACxBtG,IACDA,EAAQ,GAEPC,IACDA,EAAMmG,EAAShF,cAEbpB,GAASC,EA5BnB,uBA6Bc,IAAIyF,UAAU,8EA7B5B,WA+BQ1F,IAAUC,EA/BlB,oEAkCyB7D,KAAKwJ,MAAMW,eAAe3H,EAASoB,EAAOC,EAAK+F,GAlCxE,QAkCU3D,EAlCV,QAmCI,EAAIvE,EAAOuI,kBAAkBC,GAGpBvL,EAAI,EAtCjB,aAsCoBA,EAAIsH,EAAOjH,QAtC/B,uBAuCcoL,EAAOnE,EAAOtH,GAAGmB,eACZE,KAAKoJ,gBAxCxB,uBAyCkB,IAAInG,MAAJ,oCAAuCmH,EAAKC,iBAA5C,4CAAgGrK,KAAKoJ,eAAeiB,iBAApH,MAzClB,QAsCuC1L,GAAK,EAtC5C,wBA6CQ2L,EAAOC,KAAKC,MACPC,EAAW,EA9CxB,aA8C2BA,EAAWxE,EAAOjH,QA9C7C,wBA+CY0L,OA/CZ,EAgDc5D,EAAIb,EAAOwE,GAhDzB,UAiDyDzK,KAAKyJ,WAAW5I,IAAIiG,EAAErC,WAAYqC,EAAGoD,GAjD9F,iBAiDgBS,EAjDhB,EAiDgBA,OAAQC,EAjDxB,EAiDwBA,WAAYC,EAjDpC,EAiDoCA,YACtBC,GAAgC,qBAAhBC,YAChB,IAAIA,YAAY,SAASC,OAAOL,GAChCA,EAAOlG,YAAYwG,MAAM,OACzBC,OACN,EAAIxJ,EAAOuI,kBAAkBC,GACzBiB,EAAarE,EAAEnH,KAAKyL,aACpBC,OAxDZ,EAyDiB1M,EAAI,EAzDrB,aAyDwBA,EAAImM,EAAM9L,QAzDlC,iBA2DY,IADMsM,EAAOR,EAAMnM,GACd0M,EAAM,EAAGF,GAAcN,EAAWQ,GAAMA,GAAO,GA3DhE,KA6DkDrL,KAAKuL,UAAUvB,EAAUxH,EAASoB,EAAOC,EAAKyH,GAA5EE,EA7DpB,EA6DoBA,gBAAiBC,EA7DrC,EA6DqCA,gBAEO1L,IAA5B2K,QACoB3K,IAApByL,GACAd,EAA0Bc,GAjE1C,uBAkEsB,IAAIvI,MAAJ,gDAAmDyH,EAAnD,cAAgFc,EAAhF,2CAlEtB,WAoEYd,EAA0Bc,GACtBC,EArEhB,iBAsEgB5B,EAASyB,EAAKI,OASd,IAAAd,EAAWS,IAAmBF,EAAaN,EAAWQ,KA/EtE,kCAiFyCtL,IAApByL,GAAiCA,GAAmB3H,GAjFzE,sDAuFYsH,GAAcG,EAAKtM,OAAS,IAExBsL,EAAOC,KAAKC,MAAQ,KAzFpC,wBA0FgBF,EAAOC,KAAKC,OACZ,EAAI9I,EAAOuI,kBAAkBC,GA3F7C,UA4FsBxB,EAAQ,GA5F9B,QAyD0C/J,GAAK,EAzD/C,wBA8CqD8L,GAAY,EA9CjE,iE,iHAiGA,qGAAkBhI,EAAlB,+BAAyB,GAAzB,kBACWzC,KAAKwJ,MAAMO,YAAYtH,IADlC,gD,8GAUA,yHAAsBA,EAAtB,+BAA6B,GAA7B,SAC4DzC,KAAK+J,YAAYtH,GAD7E,uBACYqD,EADZ,EACYA,cAAe/B,EAD3B,EAC2BA,SAAUsC,EADrC,EACqCA,cACjC,EAAI3E,EAAOuI,kBAAkBxH,EAAKyH,QAC5ByB,EAAW7F,GAAiBA,EAAczF,cAC1CyF,EAAczF,cAAgBgG,EAC9BA,EALV,UAQsBrG,KAAK4L,YAAY,EAAGD,EAAUlJ,GARpD,eAQQS,EARR,QASI,EAAIxB,EAAOuI,kBAAkBxH,EAAKyH,QATtC,qBAWsB,EAAI3I,EAAkBoD,OAAOzB,GAXnD,QAWQA,EAXR,gEAcQ2I,QAAQC,MAAR,MACM,IAAI7I,MAAJ,oCAEuB,KAAE8I,KAFzB,yBAE8CJ,EAF9C,oBAfd,YAoBQ5H,EApBR,iBAsBYiI,GAAe,EACbC,EAAc,KAAKC,WAAW,GAC9BC,EAAWpI,EAASmI,WAAW,GAC5BvN,EAAI,EAzBrB,aAyBwBA,EAAIuE,EAAMlE,QAzBlC,oBA0BgBL,IAAMqN,EAAc,GAAK9I,EAAMvE,KAAOwN,EA1BtD,qDA6BgBjJ,EAAMvE,KAAOsN,IACbD,EAAcrN,GA9B9B,QAyB0CA,GAAK,EAzB/C,wBAiCQuE,EAAQA,EAAMmB,MAAM,EAAG2H,EAAc,GAjC7C,iCAmCW9I,GAnCX,2D,wGA2CA,uGAAgBT,EAAhB,+BAAuB,GAAvB,SACwBzC,KAAKoM,gBAAgB3J,GAD7C,cACUS,EADV,QAEI,EAAIxB,EAAOuI,kBAAkBxH,EAAKyH,QAFtC,kBAGWhH,EAAMuB,SAAS,SAH1B,gD,wHAaA,uGAAgChC,EAAhC,+BAAuC,GAAvC,SAC2BzC,KAAK+J,YAAYtH,GAD5C,cACUuH,EADV,yBAEWA,EAAS3G,aAFpB,gD,6EAcA,WAAgEgJ,EAAeC,EAAaC,EAAWjB,GAAM,IAAjG5H,EAAiG,EAAjGA,cAAeK,EAAkF,EAAlFA,SAAUP,EAAwE,EAAxEA,eAAgBC,EAAwD,EAAxDA,OAEjD,GAAI6H,EAAKkB,OAAO,KAAOzI,EACnB,MAAO,CAAE0H,UAAU,GAGvB,IAAM9H,EAAoBD,EAApBC,IAAKC,EAAeF,EAAfE,MAAOC,EAAQH,EAARG,IACbF,IACDA,EAAM,GAELC,IACDA,EAAQ,GAEPC,IACDA,EAAM,GAEK,QAAXJ,IACAI,EAAM,GAUV,IARA,IAAM4I,EAAYxK,KAAKwE,IAAI9C,EAAKC,EAAOC,GAInC6I,EAAsB,EACtBC,EAAqB,EACrBC,EAAS,GACTpB,GAAmBqB,EAAAA,EACdlO,EAAI,EAAGA,EAAI2M,EAAKtM,OAAS,EAAGL,GAAK,EACtC,GAAgB,OAAZ2M,EAAK3M,IAAeA,IAAM2M,EAAKtM,OAAQ,CACvC,GAAI0N,IAAwB/I,GACxB,GAAI3D,KAAK0E,aAAa4G,EAAKjH,MAAMsI,EAAoBhO,MACjD0N,EACA,MAAO,CAAEZ,UAAU,QAGtB,GAAIiB,IAAwB9I,EAAO,CAMpC,GALA4H,EAAkBsB,SAASxB,EAAKjH,MAAMsI,EAAoBhO,GAAI,IAEvC,mBAAnB6E,IACAgI,GAAmB,GAEnBA,GAAmBe,EACnB,MAAO,CAAEf,gBAAAA,EAAiBC,UAAU,GAExC,IAAY,IAAR5H,GAAaA,IAAQD,IAEjB4H,EAAkB,GAAKc,EACvB,MAAO,CAAEd,gBAAAA,EAAiBC,UAAU,QAI3C,GAAe,QAAXhI,GAA4C,IAAxBiJ,EACzBE,EAAStB,EAAKjH,MAAMsI,EAAoBhO,QAEvC,GAAI+N,IAAwB7I,EAAK,CASlC,IANe,QAAXJ,EACgBzD,KAAK+M,WAAWvB,EAAiBoB,EAAQtB,EAAKjH,MAAMsI,EAAoBhO,IAGxEmO,SAASxB,EAAKjH,MAAMsI,EAAoBhO,GAAI,MAE3C2N,EACjB,MAAO,CAAEb,UAAU,GAK3B,GAFAkB,EAAqBhO,EAAI,GACzB+N,GAAuB,GACGD,EACtB,MAIZ,MAAO,CAAEjB,gBAAAA,EAAiBC,UAAU,K,wBAExC,SAAWD,EAAiBoB,EAAQI,GAChC,IAAIC,EAAgBzB,EAAkBoB,EAAO5N,OAMvCkO,GAAwC,IAAhCF,EAAK/N,QAAQ,cAC3B,GAAgB,MAAZ+N,EAAK,IAAeE,GAcnB,GAAIA,EACL,OAAO1B,EAAkB,OAbzB,IADA,IAAI2B,EAAW,IACNzH,EAAI,EAAGA,EAAIsH,EAAKhO,OAAQ0G,GAAK,EAAG,CACrC,GAAiB,MAAbyH,GAA6C,SAAzBH,EAAK3I,MAAMqB,EAAGA,EAAI,GAAe,CACrD,IAAI0H,EAAWJ,EAAK/N,QAAQ,IAAKyG,IACf,IAAd0H,IACAA,EAAWJ,EAAKhO,QAEpBiO,EAAgBH,SAASE,EAAK3I,MAAMqB,EAAI,EAAG0H,GAAW,IACtD,MAEJD,EAAWH,EAAKtH,GAMxB,OAAOuH,I,kDAOX,WAAgBzK,GAAhB,wFAAyBC,EAAzB,+BAAgC,GAAhC,kBACWzC,KAAKwJ,MAAMxG,UAAUR,EAASC,IADzC,gD,2GAGA,WAAkB4K,EAAUC,GAA5B,8FAA4C7K,EAA5C,+BAAmD,GAAnD,SACwCzC,KAAK4E,WAAW2I,KAAKC,EAAOC,MAAMH,GAAiB,EAAGA,EAAgBD,EAAU5K,GADxH,uBACYiL,EADZ,EACYA,UAAW/C,EADvB,EACuBA,OADvB,kBAEW+C,EAAYJ,EAAiB3C,EAAOtG,MAAM,EAAGqJ,GAAa/C,GAFrE,gD,2GAUA,WAAgBgD,GAAhB,0FAAuBlL,EAAvB,+BAA8B,GAA9B,SAGiCzC,KAAK4L,YAAY+B,EAAMhO,KAAKU,cAAesN,EAAM7N,cAAe2C,GAHjG,cAGUmL,EAHV,mCAKe,EAAIrM,EAAkBsM,iBAAiBD,EAAgBD,IALtE,sCAQc,IAAI1K,MAAJ,oCAAuC0K,EAAMlJ,WAA7C,mBARd,yD,2DArXE+C,GAiYNjJ,EAAAA,QAAkBiJ,G,uLCjZdlH,EAAmBN,MAAQA,KAAKM,kBAAqBzB,OAAO0B,OAAU,SAASC,EAAGC,EAAGC,EAAGC,QAC7EZ,IAAPY,IAAkBA,EAAKD,GAC3B7B,OAAOW,eAAegB,EAAGG,EAAI,CAAEC,YAAY,EAAMC,IAAK,WAAa,OAAOJ,EAAEC,OAC1E,SAASF,EAAGC,EAAGC,EAAGC,QACTZ,IAAPY,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,KAEVI,EAAsBd,MAAQA,KAAKc,qBAAwBjC,OAAO0B,OAAU,SAASC,EAAGO,GACxFlC,OAAOW,eAAegB,EAAG,UAAW,CAAEI,YAAY,EAAMnB,MAAOsB,KAC9D,SAASP,EAAGO,GACbP,EAAC,QAAcO,IAEfC,EAAgBhB,MAAQA,KAAKgB,cAAiB,SAAUC,GACxD,GAAIA,GAAOA,EAAI5B,WAAY,OAAO4B,EAClC,IAAIC,EAAS,GACb,GAAW,MAAPD,EAAa,IAAK,IAAIP,KAAKO,EAAe,YAANP,GAAmB7B,OAAOK,UAAUiC,eAAe/B,KAAK6B,EAAKP,IAAIJ,EAAgBY,EAAQD,EAAKP,GAEtI,OADAI,EAAmBI,EAAQD,GACpBC,GAEPE,EAAmBpB,MAAQA,KAAKoB,iBAAoB,SAAUH,GAC9D,OAAQA,GAAOA,EAAI5B,WAAc4B,EAAM,CAAE,QAAWA,IAExDpC,OAAOW,eAAejB,EAAS,aAAc,CAAEkB,OAAO,IACtD,IAAM4B,EAASD,EAAgBE,EAAQ,QACjCE,EAAkBR,EAAaM,EAAQ,QACvCG,EAAUL,EAAgBE,EAAQ,QAClCC,EAAoBD,EAAQ,OAC5BI,EAASJ,EAAQ,MACjBK,EAAcP,EAAgBE,EAAQ,QACtCwM,EAAY,SAKlB,SAASlH,EAASK,EAAKpD,GAGnB,MAAO,CACH,CAAC,EAAG,GACJ,CAAC,IAJLoD,GAAO,IAIU,IAAK,IAHtBpD,GAAO,IAG2B,KAC9B,CAAC,GAAKoD,GAAO,IAAK,GAAKpD,GAAO,KAC9B,CAAC,IAAMoD,GAAO,IAAK,IAAMpD,GAAO,KAChC,CAAC,KAAOoD,GAAO,IAAK,KAAOpD,GAAO,KAClC,CAAC,MAAQoD,GAAO,IAAK,MAAQpD,GAAO,M,IAGtCkK,EAAAA,SAAAA,G,sIACF,WAAgBvL,GAAhB,8FAAyBC,EAAzB,+BAAgC,GAAhC,SAC4BzC,KAAK0C,MAAMD,GADvC,UACUE,EADV,iDAGgB,GAHhB,UAKUC,EAAQD,EAAUE,YAAYL,GACxBG,EAAUG,QAAQF,GANlC,2CAQgB,GARhB,aAUYG,EAAUJ,EAAUG,QAAQF,GAA5BG,OAVZ,0CAYeA,EAAMC,WAZrB,kCAcY,GAdZ,iD,sGAkBA,kJAAaP,EAAb,+BAAoB,GAApB,KAC4BlB,EAAkBoD,MAD9C,SAC4D3E,KAAK4E,WAAWC,SAASpC,GADrF,4DACUS,EADV,QAEI,EAAIxB,EAAOuI,kBAAkBxH,EAAKyH,QAE9BhH,EAAM4B,aAAa,KAAOgJ,EAJlC,uBAKc,IAAI7K,MAAM,kBALxB,WASUkC,EAAWjC,EAAMK,YAAY,GAC7BD,EAAcJ,EAAMK,YAAY,GAChCC,EAA+B,MAAdF,EAAwB,uBAAyB,iBAMlEG,EALa,CACf,EAAG,UACH,EAAG,MACH,EAAG,OAEiC,GAAdH,GAjB9B,uBAmBc,IAAIL,MAAJ,4CAA+CK,IAnB7D,eAqBUI,EAAgB,CAClBC,IAAKT,EAAMK,YAAY,IACvBK,MAAOV,EAAMK,YAAY,IACzBM,IAAKX,EAAMK,YAAY,KAErBO,EAAYZ,EAAMK,YAAY,IAE9BlB,IAAiB,GAAoB,IADrCC,EAAQ,GACwB,IAAW,GAAK,EAChD0C,EA7BV,SA6ByB,EAAM,GAAa,EAAR1C,GAC1ByB,EAAWD,EAAYE,OAAOC,aAAaH,GAAa,KACxDI,EAAYhB,EAAMK,YAAY,IAE9BY,EAAoBjB,EAAMK,YAAY,IAjChD,EAkCyCvD,KAAKoE,gBAAgBlB,EAAMmB,MAAM,GAAI,GAAKF,IAAvEtB,EAlCZ,EAkCYA,YAAaQ,EAlCzB,EAkCyBA,YAEjB+B,EAAa,GAAKjB,EAEhBrB,EAAU,IAAIuC,MAAMF,GAAUG,KAAK,GAAGC,KAAI,WAE5C,IAAMC,EAAWtC,EAAMK,YAAY6B,GACnCA,GAAc,EAGd,IAFA,IACIrC,EADE0C,EAAW,GAERC,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAAG,CAClC,IAAM7F,EAAMqD,EAAM4B,aAAaM,GAE/B,GADAA,GAAc,EACVvF,EAAMwC,EAAe,EACrB,MAAM,IAAIY,MAAM,8DAEf,GAAIpD,IAAQwC,EAAe,EAAG,CAC/B,IAAM2D,EAAa9C,EAAMK,YAAY6B,GACrCA,GAAc,EACK,IAAfY,IACAjD,EAAQ,EAAK4C,eAAezC,EAAOkC,IAEvCA,GAAc,GAAKY,MAElB,CACD,IAAMA,EAAa9C,EAAMK,YAAY6B,GACrCA,GAAc,EAEd,IADA,IAAMa,EAAS,IAAIZ,MAAMW,GAChBtF,EAAI,EAAGA,EAAIsF,EAAYtF,GAAK,EAAG,CACpC,IAAMwF,GAAI,EAAI1E,EAAgBqE,WAAW3C,EAAOkC,GAC1CrE,GAAI,EAAIS,EAAgBqE,WAAW3C,EAAOkC,EAAa,GAC7DA,GAAc,GACdU,EAAgB,EAAKC,eAAeD,EAAeI,GACnDD,EAAOvF,GAAK,IAAIe,EAAQ0E,QAAQD,EAAGnF,EAAGlB,GAE1C4F,EAAS5F,GAAOoG,GAIxB,IAAM+H,EAAc9K,EAAMK,YAAY6B,GACtCA,GAAc,EAEd,IADA,IAAM6I,EAAc,IAAI5I,MAAM2I,GACrBtN,EAAI,EAAGA,EAAIsN,EAAatN,GAAK,EAClCuN,EAAYvN,IAAK,EAAIc,EAAgBqE,WAAW3C,EAAOkC,GACvDA,GAAc,EACdU,EAAgB,EAAKC,eAAeD,EAAemI,EAAYvN,IAEnE,MAAO,CAAE+E,SAAAA,EAAUwI,YAAAA,EAAalL,MAAAA,MAjFxC,kBAmFW,CACHD,QAAAA,EACAiB,SAAAA,EACA1B,aAAAA,EACA2C,aAAAA,EACAd,UAAAA,EACA4B,cAAAA,EACApC,cAAAA,EACAF,eAAAA,EACAC,OAAAA,EACAJ,YAAAA,EACAR,YAAAA,EACAwD,aAAc,QA/FtB,iD,kFAkGA,SAAenD,EAAOC,GAElB,MAAO,CAAEH,WADS,EAAItB,EAAO4E,cAAcjF,EAAO8E,QAAQI,YAAYrD,EAAMmB,MAAMlB,EAAS,GAAIA,EAAS,KAAK,O,6BAGjH,SAAgBmB,GAKZ,IAJA,IAAIC,EAAY,EACZC,EAAgB,EACdnB,EAAc,GACdR,EAAc,GACXlE,EAAI,EAAGA,EAAI2F,EAAWtF,OAAQL,GAAK,EACxC,IAAK2F,EAAW3F,GAAI,CAChB,GAAI6F,EAAgB7F,EAAG,CACnB,IAAI6D,EAAU8B,EAAWG,SAAS,OAAQD,EAAe7F,GACzD6D,EAAUxC,KAAK0E,aAAalC,GAC5Ba,EAAYkB,GAAa/B,EACzBK,EAAYL,GAAW+B,EAE3BC,EAAgB7F,EAAI,EACpB4F,GAAa,EAGrB,MAAO,CAAE1B,YAAAA,EAAaQ,YAAAA,K,uDAE1B,WAAqBb,EAASgE,EAAKC,GAAnC,8HAAwChE,EAAxC,+BAA+C,GACvC+D,EAAM,IACNA,EAAM,GAFd,SAI4BxG,KAAK0C,MAAMD,GAJvC,UAIUE,EAJV,gDAMe,IANf,UAQUC,EAAQD,EAAUE,YAAYL,GAC9BkE,EAAK/D,EAAUG,QAAQF,GATjC,0CAWe,IAXf,SAasB8D,EAAGuH,YAAYjP,OAC3B0H,EAAGuH,YAAYzH,GA1KN,IA0K+BE,EAAGuH,YAAYjP,OACnD0H,EAAGuH,YAAYjP,OAAS,EACxBwH,GA5KK,IA6KT,IAAIhF,EAAgB2E,QAAQ,EAAG,KAEjC0F,QAAQqC,KAAK,4CAGXvH,EAAkBC,EAASJ,EAAKC,GAChCR,EAAS,GAvBnB,IAyB+BU,GAzB/B,IAyBI,2BACI,IADwC,eAAhC/C,EAAgC,KAAzBC,EAAyB,KAC/BhE,EAAM+D,EAAO/D,GAAOgE,EAAKhE,IAC9B,GAAI6G,EAAGjB,SAAS5F,GAEZ,IADMgH,EAAYH,EAAGjB,SAAS5F,GACrBiH,EAAI,EAAGA,EAAID,EAAU7H,SAAU8H,EACpCb,EAAOc,KAAK,IAAItF,EAAQ0E,QAAQU,EAAUC,GAAGnH,KAAMkH,EAAUC,GAAGlH,KAAMC,IA9B1F,8BAyCI,IAJMsO,EAAQzH,EAAGuH,YAAYjP,OACzBoP,EAAS,KACPC,EAASpM,KAAKuE,IAAIA,GAAO,GAAI2H,EAAQ,GACrCG,EAASrM,KAAKuE,IAAIC,GAAO,GAAI0H,EAAQ,GAClCxP,EAAI0P,EAAQ1P,GAAK2P,IAAU3P,GAC1B4P,EAAK7H,EAAGuH,YAAYtP,OAEjByP,GAAUG,EAAGnO,UAAUgO,GAAU,KAClCA,EAASG,GA7CzB,0BAiDW,EAAI7M,EAAOsF,gBAAgBf,EAAQmI,IAjD9C,iD,+DA5IEL,CAAmBpM,EAAYwE,SAgMrC5H,EAAAA,QAAkBwP,G,mKC9OlBlP,OAAOW,eAAejB,EAAS,aAAc,CAAEkB,OAAO,IACtDlB,EAAQyI,eAAiBzI,EAAQiQ,eAAiBjQ,EAAQkQ,gBAAkBlQ,EAAQ0L,iBAAmB1L,EAAQ+H,kBAAe,EAQ9H/H,EAAQ+H,aAPR,SAAsBoI,GAClB,GAAIA,EAAKC,YAAYC,OAAOC,mBACxBH,EAAKI,SAASF,OAAOG,kBACrB,MAAM,IAAI9L,MAAM,oBAEpB,OAAOyL,EAAKM,Y,IAGVC,EAAAA,SAAAA,G,oFAAAA,C,EAAmBhM,QAazB,SAASgH,EAAiBC,GACtB,GAAKA,GAGDA,EAAOgF,QAAS,CAEhB,GAA4B,qBAAjBC,aAEP,MAAM,IAAIA,aAAa,UAAW,cAGlC,IAAM7H,EAAI,IAAI2H,EAAW,WAEzB,MADA3H,EAAEyE,KAAO,cACHzE,G,gCAWlB,WAA+B4C,GAA/B,+EACUtB,QAAQC,UADlB,OAEIoB,EAAiBC,GAFrB,4C,sBAKA,SAASsE,EAAeY,EAAQC,GAC5B,OAAQA,EAAO1P,KAAKU,cAAgB+O,EAAOxP,KAAKS,cAAgB,MAC5DgP,EAAOzP,KAAKS,cAAgB+O,EAAOzP,KAAKU,cAAgB,IAdhE9B,EAAQ0L,iBAAmBA,EAW3B1L,EAAQkQ,gB,SAJuB,G,gCAS/BlQ,EAAQiQ,eAAiBA,EAwCzBjQ,EAAQyI,eAvCR,SAAwBf,EAAQmI,GAC5B,IAAMkB,EAAe,GACjBC,EAAY,KAChB,OAAsB,IAAlBtJ,EAAOjH,OACAiH,GAEXA,EAAOuJ,MAAK,SAAUC,EAAIC,GACtB,IAAMC,EAAMF,EAAG9P,KAAKU,cAAgBqP,EAAG/P,KAAKU,cAC5C,OAAY,IAARsP,EACOA,EAGAF,EAAG9P,KAAKyL,aAAesE,EAAG/P,KAAKyL,gBAG9CnF,EAAO2J,SAAQ,SAAAjC,KACNS,GAAUT,EAAM/N,KAAKQ,UAAUgO,GAAU,KACxB,OAAdmB,GACAD,EAAavI,KAAK4G,GAClB4B,EAAY5B,GAGRa,EAAee,EAAW5B,GACtBA,EAAM/N,KAAKQ,UAAUmP,EAAU3P,MAAQ,IACvC2P,EAAU3P,KAAO+N,EAAM/N,OAI3B0P,EAAavI,KAAK4G,GAClB4B,EAAY5B,OAQrB2B,K,6EC9FXzQ,OAAOW,eAAejB,EAAS,aAAc,CAAEkB,OAAO,IACtDlB,EAAQsH,eAAY,E,IACdgK,EAAAA,WACF,WAAYxP,EAAe+K,GAAc,UACrCpL,KAAKK,cAAgBA,EACrBL,KAAKoL,aAAeA,E,kCAExB,WACI,gBAAUpL,KAAKK,cAAf,YAAgCL,KAAKoL,gB,uBAEzC,SAAUjL,GACN,OAAQH,KAAKK,cAAgBF,EAAEE,eAAiBL,KAAKoL,aAAejL,EAAEiL,gB,kBAE1E,WAAoB,IAChB,IAAI5E,EACA7H,EAAI,EAFQ,mBAANyD,EAAM,yBAANA,EAAM,gBAGhB,MAAQoE,EAAK7H,GAAK,EACd6H,EAAMpE,EAAKzD,GAEf,KAAOA,EAAIyD,EAAKpD,OAAQL,GAAK,EACrB6H,EAAIpG,UAAUgC,EAAKzD,IAAM,IACzB6H,EAAMpE,EAAKzD,IAGnB,OAAO6H,M,EAtBTqJ,GAyBNtR,EAAAA,QAAkBsR,EAYlBtR,EAAQsH,UAXR,SAAmB3C,GAAsC,IAA/BC,EAA+B,uDAAtB,EAAG2M,EAAmB,wDACrD,GAAIA,EACA,MAAM,IAAI7M,MAAM,mDAEpB,OAAO,IAAI4M,EAAkC,cAApB3M,EAAMC,EAAS,GAChB,WAApBD,EAAMC,EAAS,GACK,SAApBD,EAAMC,EAAS,GACK,MAApBD,EAAMC,EAAS,GACK,IAApBD,EAAMC,EAAS,GACfD,EAAMC,EAAS,GAAKD,EAAMC,EAAS,IAAM,EAAKD,EAAMC","sources":["../../../node_modules/@babel/runtime/helpers/objectWithoutProperties.js","../../../node_modules/@babel/runtime/helpers/objectWithoutPropertiesLoose.js","../../../node_modules/@gmod/tabix/esm/chunk.js","../../../node_modules/@gmod/tabix/esm/csi.js","../../../node_modules/@gmod/tabix/esm/index.js","../../../node_modules/@gmod/tabix/esm/indexFile.js","../../../node_modules/@gmod/tabix/esm/tabixIndexedFile.js","../../../node_modules/@gmod/tabix/esm/tbi.js","../../../node_modules/@gmod/tabix/esm/util.js","../../../node_modules/@gmod/tabix/esm/virtualOffset.js"],"sourcesContent":["var objectWithoutPropertiesLoose = require(\"./objectWithoutPropertiesLoose.js\");\n\nfunction _objectWithoutProperties(source, excluded) {\n  if (source == null) return {};\n  var target = objectWithoutPropertiesLoose(source, excluded);\n  var key, i;\n\n  if (Object.getOwnPropertySymbols) {\n    var sourceSymbolKeys = Object.getOwnPropertySymbols(source);\n\n    for (i = 0; i < sourceSymbolKeys.length; i++) {\n      key = sourceSymbolKeys[i];\n      if (excluded.indexOf(key) >= 0) continue;\n      if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue;\n      target[key] = source[key];\n    }\n  }\n\n  return target;\n}\n\nmodule.exports = _objectWithoutProperties, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _objectWithoutPropertiesLoose(source, excluded) {\n  if (source == null) return {};\n  var target = {};\n  var sourceKeys = Object.keys(source);\n  var key, i;\n\n  for (i = 0; i < sourceKeys.length; i++) {\n    key = sourceKeys[i];\n    if (excluded.indexOf(key) >= 0) continue;\n    target[key] = source[key];\n  }\n\n  return target;\n}\n\nmodule.exports = _objectWithoutPropertiesLoose, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// little class representing a chunk in the index\nclass Chunk {\n    /**\n     * @param {VirtualOffset} minv\n     * @param {VirtualOffset} maxv\n     * @param {number} bin\n     * @param {number} [fetchedSize]\n     */\n    constructor(minv, maxv, bin, fetchedSize = undefined) {\n        this.minv = minv;\n        this.maxv = maxv;\n        this.bin = bin;\n        this._fetchedSize = fetchedSize;\n    }\n    toUniqueString() {\n        return `${this.minv}..${this.maxv} (bin ${this.bin}, fetchedSize ${this.fetchedSize()})`;\n    }\n    toString() {\n        return this.toUniqueString();\n    }\n    compareTo(b) {\n        return (this.minv.compareTo(b.minv) ||\n            this.maxv.compareTo(b.maxv) ||\n            this.bin - b.bin);\n    }\n    fetchedSize() {\n        if (this._fetchedSize !== undefined) {\n            return this._fetchedSize;\n        }\n        return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition;\n    }\n}\nexports.default = Chunk;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst long_1 = __importDefault(require(\"long\"));\nconst bgzf_filehandle_1 = require(\"@gmod/bgzf-filehandle\");\nconst virtualOffset_1 = __importStar(require(\"./virtualOffset\"));\nconst chunk_1 = __importDefault(require(\"./chunk\"));\nconst util_1 = require(\"./util\");\nconst indexFile_1 = __importDefault(require(\"./indexFile\"));\nconst CSI1_MAGIC = 21582659; // CSI\\1\nconst CSI2_MAGIC = 38359875; // CSI\\2\nfunction lshift(num, bits) {\n    return num * 2 ** bits;\n}\nfunction rshift(num, bits) {\n    return Math.floor(num / 2 ** bits);\n}\nclass CSI extends indexFile_1.default {\n    constructor(args) {\n        super(args);\n        this.maxBinNumber = 0;\n        this.depth = 0;\n        this.minShift = 0;\n    }\n    async lineCount(refName, opts = {}) {\n        const indexData = await this.parse(opts);\n        if (!indexData) {\n            return -1;\n        }\n        const refId = indexData.refNameToId[refName];\n        const idx = indexData.indices[refId];\n        if (!idx) {\n            return -1;\n        }\n        const { stats } = indexData.indices[refId];\n        if (stats) {\n            return stats.lineCount;\n        }\n        return -1;\n    }\n    async indexCov() {\n        throw new Error('CSI indexes do not support indexcov');\n        return [];\n    }\n    parseAuxData(bytes, offset, auxLength) {\n        if (auxLength < 30) {\n            return {\n                refIdToName: [],\n                refNameToId: {},\n            };\n        }\n        const formatFlags = bytes.readInt32LE(offset);\n        const coordinateType = formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed';\n        const format = { 0: 'generic', 1: 'SAM', 2: 'VCF' }[formatFlags & 0xf];\n        if (!format) {\n            throw new Error(`invalid Tabix preset format flags ${formatFlags}`);\n        }\n        const columnNumbers = {\n            ref: bytes.readInt32LE(offset + 4),\n            start: bytes.readInt32LE(offset + 8),\n            end: bytes.readInt32LE(offset + 12),\n        };\n        const metaValue = bytes.readInt32LE(offset + 16);\n        const metaChar = metaValue ? String.fromCharCode(metaValue) : '';\n        const skipLines = bytes.readInt32LE(offset + 20);\n        const nameSectionLength = bytes.readInt32LE(offset + 24);\n        const { refIdToName, refNameToId } = this._parseNameBytes(bytes.slice(offset + 28, offset + 28 + nameSectionLength));\n        return {\n            refIdToName,\n            refNameToId,\n            skipLines,\n            metaChar,\n            columnNumbers,\n            format,\n            coordinateType,\n        };\n    }\n    _parseNameBytes(namesBytes) {\n        let currRefId = 0;\n        let currNameStart = 0;\n        const refIdToName = [];\n        const refNameToId = {};\n        for (let i = 0; i < namesBytes.length; i += 1) {\n            if (!namesBytes[i]) {\n                if (currNameStart < i) {\n                    let refName = namesBytes.toString('utf8', currNameStart, i);\n                    refName = this.renameRefSeq(refName);\n                    refIdToName[currRefId] = refName;\n                    refNameToId[refName] = currRefId;\n                }\n                currNameStart = i + 1;\n                currRefId += 1;\n            }\n        }\n        return { refNameToId, refIdToName };\n    }\n    // fetch and parse the index\n    async _parse(opts = {}) {\n        const bytes = await (0, bgzf_filehandle_1.unzip)((await this.filehandle.readFile(opts)));\n        // check TBI magic numbers\n        let csiVersion;\n        if (bytes.readUInt32LE(0) === CSI1_MAGIC) {\n            csiVersion = 1;\n        }\n        else if (bytes.readUInt32LE(0) === CSI2_MAGIC) {\n            csiVersion = 2;\n        }\n        else {\n            throw new Error('Not a CSI file');\n            // TODO: do we need to support big-endian CSI files?\n        }\n        this.minShift = bytes.readInt32LE(4);\n        this.depth = bytes.readInt32LE(8);\n        this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7;\n        const maxRefLength = 2 ** (this.minShift + this.depth * 3);\n        const auxLength = bytes.readInt32LE(12);\n        let aux = {\n            refIdToName: [],\n            refNameToId: {},\n        };\n        if (auxLength) {\n            aux = this.parseAuxData(bytes, 16, auxLength);\n        }\n        const refCount = bytes.readInt32LE(16 + auxLength);\n        // read the indexes for each reference sequence\n        let firstDataLine;\n        let currOffset = 16 + auxLength + 4;\n        const indices = new Array(refCount).fill(0).map(() => {\n            // the binning index\n            const binCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const binIndex = {};\n            let stats; // < provided by parsing a pseudo-bin, if present\n            for (let j = 0; j < binCount; j += 1) {\n                const bin = bytes.readUInt32LE(currOffset);\n                if (bin > this.maxBinNumber) {\n                    // this is a fake bin that actually has stats information\n                    // about the reference sequence in it\n                    stats = this.parsePseudoBin(bytes, currOffset + 4);\n                    currOffset += 4 + 8 + 4 + 16 + 16;\n                }\n                else {\n                    const loffset = (0, virtualOffset_1.fromBytes)(bytes, currOffset + 4);\n                    firstDataLine = this._findFirstData(firstDataLine, loffset);\n                    const chunkCount = bytes.readInt32LE(currOffset + 12);\n                    currOffset += 16;\n                    const chunks = new Array(chunkCount);\n                    for (let k = 0; k < chunkCount; k += 1) {\n                        const u = (0, virtualOffset_1.fromBytes)(bytes, currOffset);\n                        const v = (0, virtualOffset_1.fromBytes)(bytes, currOffset + 8);\n                        currOffset += 16;\n                        // this._findFirstData(data, u)\n                        chunks[k] = new chunk_1.default(u, v, bin);\n                    }\n                    binIndex[bin] = chunks;\n                }\n            }\n            return { binIndex, stats };\n        });\n        return {\n            ...aux,\n            csi: true,\n            refCount,\n            maxBlockSize: 1 << 16,\n            firstDataLine,\n            csiVersion,\n            indices,\n            depth: this.depth,\n            maxBinNumber: this.maxBinNumber,\n            maxRefLength,\n        };\n    }\n    parsePseudoBin(bytes, offset) {\n        const lineCount = (0, util_1.longToNumber)(long_1.default.fromBytesLE(Array.prototype.slice.call(bytes, offset + 28, offset + 36), true));\n        return { lineCount };\n    }\n    async blocksForRange(refName, min, max, opts = {}) {\n        if (min < 0) {\n            min = 0;\n        }\n        const indexData = await this.parse(opts);\n        if (!indexData) {\n            return [];\n        }\n        const refId = indexData.refNameToId[refName];\n        const ba = indexData.indices[refId];\n        if (!ba) {\n            return [];\n        }\n        // const { linearIndex, binIndex } = indexes\n        const overlappingBins = this.reg2bins(min, max); // List of bin #s that overlap min, max\n        const chunks = [];\n        // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n        for (const [start, end] of overlappingBins) {\n            for (let bin = start; bin <= end; bin++) {\n                if (ba.binIndex[bin]) {\n                    const binChunks = ba.binIndex[bin];\n                    for (let c = 0; c < binChunks.length; ++c) {\n                        chunks.push(new chunk_1.default(binChunks[c].minv, binChunks[c].maxv, bin));\n                    }\n                }\n            }\n        }\n        return (0, util_1.optimizeChunks)(chunks, new virtualOffset_1.default(0, 0));\n    }\n    /**\n     * calculate the list of bins that may overlap with region [beg,end) (zero-based half-open)\n     */\n    reg2bins(beg, end) {\n        beg -= 1; // < convert to 1-based closed\n        if (beg < 1) {\n            beg = 1;\n        }\n        if (end > 2 ** 50) {\n            end = 2 ** 34;\n        } // 17 GiB ought to be enough for anybody\n        end -= 1;\n        let l = 0;\n        let t = 0;\n        let s = this.minShift + this.depth * 3;\n        const bins = [];\n        for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n            const b = t + rshift(beg, s);\n            const e = t + rshift(end, s);\n            if (e - b + bins.length > this.maxBinNumber) {\n                throw new Error(`query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`);\n            }\n            bins.push([b, e]);\n        }\n        return bins;\n    }\n}\nexports.default = CSI;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.CSI = exports.TBI = exports.TabixIndexedFile = void 0;\nconst tabixIndexedFile_1 = __importDefault(require(\"./tabixIndexedFile\"));\nexports.TabixIndexedFile = tabixIndexedFile_1.default;\nconst tbi_1 = __importDefault(require(\"./tbi\"));\nexports.TBI = tbi_1.default;\nconst csi_1 = __importDefault(require(\"./csi\"));\nexports.CSI = csi_1.default;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortable_promise_cache_1 = __importDefault(require(\"abortable-promise-cache\"));\nconst quick_lru_1 = __importDefault(require(\"quick-lru\"));\nclass IndexFile {\n    /**\n     * @param {filehandle} filehandle\n     * @param {function} [renameRefSeqs]\n     */\n    constructor({ filehandle, renameRefSeqs = (n) => n, }) {\n        this.filehandle = filehandle;\n        this.renameRefSeq = renameRefSeqs;\n    }\n    async getMetadata(opts = {}) {\n        // eslint-disable-next-line @typescript-eslint/no-unused-vars\n        const { indices, ...rest } = await this.parse(opts);\n        return rest;\n    }\n    _findFirstData(currentFdl, virtualOffset) {\n        if (currentFdl) {\n            return currentFdl.compareTo(virtualOffset) > 0\n                ? virtualOffset\n                : currentFdl;\n        }\n        else {\n            return virtualOffset;\n        }\n    }\n    async parse(opts = {}) {\n        if (!this._parseCache) {\n            this._parseCache = new abortable_promise_cache_1.default({\n                cache: new quick_lru_1.default({ maxSize: 1 }),\n                fill: () => this._parse(opts),\n            });\n        }\n        return this._parseCache.get('index', null, undefined);\n    }\n    async hasRefSeq(seqId, opts = {}) {\n        return !!((await this.parse(opts)).indices[seqId] || {}).binIndex;\n    }\n}\nexports.default = IndexFile;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortable_promise_cache_1 = __importDefault(require(\"abortable-promise-cache\"));\nconst quick_lru_1 = __importDefault(require(\"quick-lru\"));\nconst generic_filehandle_1 = require(\"generic-filehandle\");\nconst bgzf_filehandle_1 = require(\"@gmod/bgzf-filehandle\");\nconst util_1 = require(\"./util\");\nconst tbi_1 = __importDefault(require(\"./tbi\"));\nconst csi_1 = __importDefault(require(\"./csi\"));\nfunction timeout(time) {\n    return new Promise(resolve => {\n        setTimeout(resolve, time);\n    });\n}\nclass TabixIndexedFile {\n    /**\n     * @param {object} args\n     * @param {string} [args.path]\n     * @param {filehandle} [args.filehandle]\n     * @param {string} [args.tbiPath]\n     * @param {filehandle} [args.tbiFilehandle]\n     * @param {string} [args.csiPath]\n     * @param {filehandle} [args.csiFilehandle]\n     * @param {chunkSizeLimit} default 50MiB\n     * @param {function} [args.renameRefSeqs] optional function with sig `string => string` to transform\n     * reference sequence names for the purpose of indexing and querying. note that the data that is returned is\n     * not altered, just the names of the reference sequences that are used for querying.\n     * @param {number} [args.chunkCacheSize] maximum size in bytes of the chunk cache. default 5MB\n     * @param {number} [args.blockCacheSize] maximum size in bytes of the block cache. default 5MB\n     */\n    constructor({ path, filehandle, tbiPath, tbiFilehandle, csiPath, csiFilehandle, chunkSizeLimit = 50000000, renameRefSeqs = n => n, chunkCacheSize = 5 * 2 ** 20, }) {\n        if (filehandle) {\n            this.filehandle = filehandle;\n        }\n        else if (path) {\n            this.filehandle = new generic_filehandle_1.LocalFile(path);\n        }\n        else {\n            throw new TypeError('must provide either filehandle or path');\n        }\n        if (tbiFilehandle) {\n            this.index = new tbi_1.default({\n                filehandle: tbiFilehandle,\n                renameRefSeqs,\n            });\n        }\n        else if (csiFilehandle) {\n            this.index = new csi_1.default({\n                filehandle: csiFilehandle,\n                renameRefSeqs,\n            });\n        }\n        else if (tbiPath) {\n            this.index = new tbi_1.default({\n                filehandle: new generic_filehandle_1.LocalFile(tbiPath),\n                renameRefSeqs,\n            });\n        }\n        else if (csiPath) {\n            this.index = new csi_1.default({\n                filehandle: new generic_filehandle_1.LocalFile(csiPath),\n                renameRefSeqs,\n            });\n        }\n        else if (path) {\n            this.index = new tbi_1.default({\n                filehandle: new generic_filehandle_1.LocalFile(`${path}.tbi`),\n                renameRefSeqs,\n            });\n        }\n        else {\n            throw new TypeError('must provide one of tbiFilehandle, tbiPath, csiFilehandle, or csiPath');\n        }\n        this.chunkSizeLimit = chunkSizeLimit;\n        this.renameRefSeq = renameRefSeqs;\n        this.chunkCache = new abortable_promise_cache_1.default({\n            cache: new quick_lru_1.default({\n                maxSize: Math.floor(chunkCacheSize / (1 << 16)),\n            }),\n            fill: this.readChunk.bind(this),\n        });\n    }\n    /**\n     * @param {string} refName name of the reference sequence\n     * @param {number} start start of the region (in 0-based half-open coordinates)\n     * @param {number} end end of the region (in 0-based half-open coordinates)\n     * @param {function|object} lineCallback callback called for each line in the region. can also pass a object param containing obj.lineCallback, obj.signal, etc\n     * @returns {Promise} resolved when the whole read is finished, rejected on error\n     */\n    async getLines(refName, start, end, opts) {\n        let signal;\n        let options = {};\n        let callback;\n        if (typeof opts === 'undefined') {\n            throw new TypeError('line callback must be provided');\n        }\n        if (typeof opts === 'function') {\n            callback = opts;\n        }\n        else {\n            options = opts;\n            callback = opts.lineCallback;\n        }\n        if (refName === undefined) {\n            throw new TypeError('must provide a reference sequence name');\n        }\n        if (!callback) {\n            throw new TypeError('line callback must be provided');\n        }\n        const metadata = await this.index.getMetadata(options);\n        (0, util_1.checkAbortSignal)(signal);\n        if (!start) {\n            start = 0;\n        }\n        if (!end) {\n            end = metadata.maxRefLength;\n        }\n        if (!(start <= end)) {\n            throw new TypeError('invalid start and end coordinates. start must be less than or equal to end');\n        }\n        if (start === end) {\n            return;\n        }\n        const chunks = await this.index.blocksForRange(refName, start, end, options);\n        (0, util_1.checkAbortSignal)(signal);\n        // check the chunks for any that are over the size limit.  if\n        // any are, don't fetch any of them\n        for (let i = 0; i < chunks.length; i += 1) {\n            const size = chunks[i].fetchedSize();\n            if (size > this.chunkSizeLimit) {\n                throw new Error(`Too much data. Chunk size ${size.toLocaleString()} bytes exceeds chunkSizeLimit of ${this.chunkSizeLimit.toLocaleString()}.`);\n            }\n        }\n        // now go through each chunk and parse and filter the lines out of it\n        let last = Date.now();\n        for (let chunkNum = 0; chunkNum < chunks.length; chunkNum += 1) {\n            let previousStartCoordinate;\n            const c = chunks[chunkNum];\n            const { buffer, cpositions, dpositions } = await this.chunkCache.get(c.toString(), c, signal);\n            const lines = (typeof TextDecoder !== 'undefined'\n                ? new TextDecoder('utf-8').decode(buffer)\n                : buffer.toString()).split('\\n');\n            lines.pop();\n            (0, util_1.checkAbortSignal)(signal);\n            let blockStart = c.minv.dataPosition;\n            let pos;\n            for (let i = 0; i < lines.length; i += 1) {\n                const line = lines[i];\n                for (pos = 0; blockStart >= dpositions[pos]; pos += 1) { }\n                // filter the line for whether it is within the requested range\n                const { startCoordinate, overlaps } = this.checkLine(metadata, refName, start, end, line);\n                // do a small check just to make sure that the lines are really sorted by start coordinate\n                if (previousStartCoordinate !== undefined &&\n                    startCoordinate !== undefined &&\n                    previousStartCoordinate > startCoordinate) {\n                    throw new Error(`Lines not sorted by start coordinate (${previousStartCoordinate} > ${startCoordinate}), this file is not usable with Tabix.`);\n                }\n                previousStartCoordinate = startCoordinate;\n                if (overlaps) {\n                    callback(line.trim(), \n                    // cpositions[pos] refers to actual file offset of a bgzip block boundaries\n                    //\n                    // we multiply by (1 <<8) in order to make sure each block has a \"unique\"\n                    // address space so that data in that block could never overlap\n                    //\n                    // then the blockStart-dpositions is an uncompressed file offset from\n                    // that bgzip block boundary, and since the cpositions are multiplied by\n                    // (1 << 8) these uncompressed offsets get a unique space\n                    cpositions[pos] * (1 << 8) + (blockStart - dpositions[pos]));\n                }\n                else if (startCoordinate !== undefined && startCoordinate >= end) {\n                    // the lines were overlapping the region, but now have stopped, so\n                    // we must be at the end of the relevant data and we can stop\n                    // processing data now\n                    return;\n                }\n                blockStart += line.length + 1;\n                // yield if we have emitted beyond the yield limit\n                if (last - Date.now() > 500) {\n                    last = Date.now();\n                    (0, util_1.checkAbortSignal)(signal);\n                    await timeout(1);\n                }\n            }\n        }\n    }\n    async getMetadata(opts = {}) {\n        return this.index.getMetadata(opts);\n    }\n    /**\n     * get a buffer containing the \"header\" region of\n     * the file, which are the bytes up to the first\n     * non-meta line\n     *\n     * @returns {Promise} for a buffer\n     */\n    async getHeaderBuffer(opts = {}) {\n        const { firstDataLine, metaChar, maxBlockSize } = await this.getMetadata(opts);\n        (0, util_1.checkAbortSignal)(opts.signal);\n        const maxFetch = firstDataLine && firstDataLine.blockPosition\n            ? firstDataLine.blockPosition + maxBlockSize\n            : maxBlockSize;\n        // TODO: what if we don't have a firstDataLine, and the header\n        // actually takes up more than one block? this case is not covered here\n        let bytes = await this._readRegion(0, maxFetch, opts);\n        (0, util_1.checkAbortSignal)(opts.signal);\n        try {\n            bytes = await (0, bgzf_filehandle_1.unzip)(bytes);\n        }\n        catch (e) {\n            console.error(e);\n            throw new Error(\n            //@ts-ignore\n            `error decompressing block ${e.code} at 0 (length ${maxFetch}) ${e}`);\n        }\n        // trim off lines after the last non-meta line\n        if (metaChar) {\n            // trim backward from the end\n            let lastNewline = -1;\n            const newlineByte = '\\n'.charCodeAt(0);\n            const metaByte = metaChar.charCodeAt(0);\n            for (let i = 0; i < bytes.length; i += 1) {\n                if (i === lastNewline + 1 && bytes[i] !== metaByte) {\n                    break;\n                }\n                if (bytes[i] === newlineByte) {\n                    lastNewline = i;\n                }\n            }\n            bytes = bytes.slice(0, lastNewline + 1);\n        }\n        return bytes;\n    }\n    /**\n     * get a string containing the \"header\" region of the\n     * file, is the portion up to the first non-meta line\n     *\n     * @returns {Promise} for a string\n     */\n    async getHeader(opts = {}) {\n        const bytes = await this.getHeaderBuffer(opts);\n        (0, util_1.checkAbortSignal)(opts.signal);\n        return bytes.toString('utf8');\n    }\n    /**\n     * get an array of reference sequence names, in the order in which\n     * they occur in the file.\n     *\n     * reference sequence renaming is not applied to these names.\n     *\n     * @returns {Promise} for an array of string sequence names\n     */\n    async getReferenceSequenceNames(opts = {}) {\n        const metadata = await this.getMetadata(opts);\n        return metadata.refIdToName;\n    }\n    /**\n     * @param {object} metadata metadata object from the parsed index,\n     * containing columnNumbers, metaChar, and format\n     * @param {string} regionRefName\n     * @param {number} regionStart region start coordinate (0-based-half-open)\n     * @param {number} regionEnd region end coordinate (0-based-half-open)\n     * @param {array[string]} line\n     * @returns {object} like `{startCoordinate, overlaps}`. overlaps is boolean,\n     * true if line is a data line that overlaps the given region\n     */\n    checkLine({ columnNumbers, metaChar, coordinateType, format, }, regionRefName, regionStart, regionEnd, line) {\n        // skip meta lines\n        if (line.charAt(0) === metaChar) {\n            return { overlaps: false };\n        }\n        // check ref/start/end using column metadata from index\n        let { ref, start, end } = columnNumbers;\n        if (!ref) {\n            ref = 0;\n        }\n        if (!start) {\n            start = 0;\n        }\n        if (!end) {\n            end = 0;\n        }\n        if (format === 'VCF') {\n            end = 8;\n        }\n        const maxColumn = Math.max(ref, start, end);\n        // this code is kind of complex, but it is fairly fast.\n        // basically, we want to avoid doing a split, because if the lines are really long\n        // that could lead to us allocating a bunch of extra memory, which is slow\n        let currentColumnNumber = 1; // cols are numbered starting at 1 in the index metadata\n        let currentColumnStart = 0;\n        let refSeq = '';\n        let startCoordinate = -Infinity;\n        for (let i = 0; i < line.length + 1; i += 1) {\n            if (line[i] === '\\t' || i === line.length) {\n                if (currentColumnNumber === ref) {\n                    if (this.renameRefSeq(line.slice(currentColumnStart, i)) !==\n                        regionRefName) {\n                        return { overlaps: false };\n                    }\n                }\n                else if (currentColumnNumber === start) {\n                    startCoordinate = parseInt(line.slice(currentColumnStart, i), 10);\n                    // we convert to 0-based-half-open\n                    if (coordinateType === '1-based-closed') {\n                        startCoordinate -= 1;\n                    }\n                    if (startCoordinate >= regionEnd) {\n                        return { startCoordinate, overlaps: false };\n                    }\n                    if (end === 0 || end === start) {\n                        // if we have no end, we assume the feature is 1 bp long\n                        if (startCoordinate + 1 <= regionStart) {\n                            return { startCoordinate, overlaps: false };\n                        }\n                    }\n                }\n                else if (format === 'VCF' && currentColumnNumber === 4) {\n                    refSeq = line.slice(currentColumnStart, i);\n                }\n                else if (currentColumnNumber === end) {\n                    let endCoordinate;\n                    // this will never match if there is no end column\n                    if (format === 'VCF') {\n                        endCoordinate = this._getVcfEnd(startCoordinate, refSeq, line.slice(currentColumnStart, i));\n                    }\n                    else {\n                        endCoordinate = parseInt(line.slice(currentColumnStart, i), 10);\n                    }\n                    if (endCoordinate <= regionStart) {\n                        return { overlaps: false };\n                    }\n                }\n                currentColumnStart = i + 1;\n                currentColumnNumber += 1;\n                if (currentColumnNumber > maxColumn) {\n                    break;\n                }\n            }\n        }\n        return { startCoordinate, overlaps: true };\n    }\n    _getVcfEnd(startCoordinate, refSeq, info) {\n        let endCoordinate = startCoordinate + refSeq.length;\n        // ignore TRA features as they specify CHR2 and END\n        // as being on a different chromosome\n        // if CHR2 is on the same chromosome, still ignore it\n        // because there should be another pairwise feature\n        // at the end of this one\n        const isTRA = info.indexOf('SVTYPE=TRA') !== -1;\n        if (info[0] !== '.' && !isTRA) {\n            let prevChar = ';';\n            for (let j = 0; j < info.length; j += 1) {\n                if (prevChar === ';' && info.slice(j, j + 4) === 'END=') {\n                    let valueEnd = info.indexOf(';', j);\n                    if (valueEnd === -1) {\n                        valueEnd = info.length;\n                    }\n                    endCoordinate = parseInt(info.slice(j + 4, valueEnd), 10);\n                    break;\n                }\n                prevChar = info[j];\n            }\n        }\n        else if (isTRA) {\n            return startCoordinate + 1;\n        }\n        return endCoordinate;\n    }\n    /**\n     * return the approximate number of data lines in the given reference sequence\n     * @param {string} refSeq reference sequence name\n     * @returns {Promise} for number of data lines present on that reference sequence\n     */\n    async lineCount(refName, opts = {}) {\n        return this.index.lineCount(refName, opts);\n    }\n    async _readRegion(position, compressedSize, opts = {}) {\n        const { bytesRead, buffer } = await this.filehandle.read(Buffer.alloc(compressedSize), 0, compressedSize, position, opts);\n        return bytesRead < compressedSize ? buffer.slice(0, bytesRead) : buffer;\n    }\n    /**\n     * read and uncompress the data in a chunk (composed of one or more\n     * contiguous bgzip blocks) of the file\n     * @param {Chunk} chunk\n     * @returns {Promise} for a string chunk of the file\n     */\n    async readChunk(chunk, opts = {}) {\n        // fetch the uncompressed data, uncompress carefully a block at a time,\n        // and stop when done\n        const compressedData = await this._readRegion(chunk.minv.blockPosition, chunk.fetchedSize(), opts);\n        try {\n            return (0, bgzf_filehandle_1.unzipChunkSlice)(compressedData, chunk);\n        }\n        catch (e) {\n            throw new Error(`error decompressing chunk ${chunk.toString()} ${e}`);\n        }\n    }\n}\nexports.default = TabixIndexedFile;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst long_1 = __importDefault(require(\"long\"));\nconst virtualOffset_1 = __importStar(require(\"./virtualOffset\"));\nconst chunk_1 = __importDefault(require(\"./chunk\"));\nconst bgzf_filehandle_1 = require(\"@gmod/bgzf-filehandle\");\nconst util_1 = require(\"./util\");\nconst indexFile_1 = __importDefault(require(\"./indexFile\"));\nconst TBI_MAGIC = 21578324; // TBI\\1\nconst TAD_LIDX_SHIFT = 14;\n/**\n * calculate the list of bins that may overlap with region [beg,end) (zero-based half-open)\n */\nfunction reg2bins(beg, end) {\n    beg += 1; // < convert to 1-based closed\n    end -= 1;\n    return [\n        [0, 0],\n        [1 + (beg >> 26), 1 + (end >> 26)],\n        [9 + (beg >> 23), 9 + (end >> 23)],\n        [73 + (beg >> 20), 73 + (end >> 20)],\n        [585 + (beg >> 17), 585 + (end >> 17)],\n        [4681 + (beg >> 14), 4681 + (end >> 14)],\n    ];\n}\nclass TabixIndex extends indexFile_1.default {\n    async lineCount(refName, opts = {}) {\n        const indexData = await this.parse(opts);\n        if (!indexData) {\n            return -1;\n        }\n        const refId = indexData.refNameToId[refName];\n        const idx = indexData.indices[refId];\n        if (!idx) {\n            return -1;\n        }\n        const { stats } = indexData.indices[refId];\n        if (stats) {\n            return stats.lineCount;\n        }\n        return -1;\n    }\n    // memoize\n    // fetch and parse the index\n    async _parse(opts = {}) {\n        const bytes = await (0, bgzf_filehandle_1.unzip)((await this.filehandle.readFile(opts)));\n        (0, util_1.checkAbortSignal)(opts.signal);\n        // check TBI magic numbers\n        if (bytes.readUInt32LE(0) !== TBI_MAGIC /* \"TBI\\1\" */) {\n            throw new Error('Not a TBI file');\n            // TODO: do we need to support big-endian TBI files?\n        }\n        // number of reference sequences in the index\n        const refCount = bytes.readInt32LE(4);\n        const formatFlags = bytes.readInt32LE(8);\n        const coordinateType = formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed';\n        const formatOpts = {\n            0: 'generic',\n            1: 'SAM',\n            2: 'VCF',\n        };\n        const format = formatOpts[formatFlags & 0xf];\n        if (!format) {\n            throw new Error(`invalid Tabix preset format flags ${formatFlags}`);\n        }\n        const columnNumbers = {\n            ref: bytes.readInt32LE(12),\n            start: bytes.readInt32LE(16),\n            end: bytes.readInt32LE(20),\n        };\n        const metaValue = bytes.readInt32LE(24);\n        const depth = 5;\n        const maxBinNumber = ((1 << ((depth + 1) * 3)) - 1) / 7;\n        const maxRefLength = 2 ** (14 + depth * 3);\n        const metaChar = metaValue ? String.fromCharCode(metaValue) : null;\n        const skipLines = bytes.readInt32LE(28);\n        // read sequence dictionary\n        const nameSectionLength = bytes.readInt32LE(32);\n        const { refNameToId, refIdToName } = this._parseNameBytes(bytes.slice(36, 36 + nameSectionLength));\n        // read the indexes for each reference sequence\n        let currOffset = 36 + nameSectionLength;\n        let firstDataLine;\n        const indices = new Array(refCount).fill(0).map(() => {\n            // the binning index\n            const binCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const binIndex = {};\n            let stats;\n            for (let j = 0; j < binCount; j += 1) {\n                const bin = bytes.readUInt32LE(currOffset);\n                currOffset += 4;\n                if (bin > maxBinNumber + 1) {\n                    throw new Error('tabix index contains too many bins, please use a CSI index');\n                }\n                else if (bin === maxBinNumber + 1) {\n                    const chunkCount = bytes.readInt32LE(currOffset);\n                    currOffset += 4;\n                    if (chunkCount === 2) {\n                        stats = this.parsePseudoBin(bytes, currOffset);\n                    }\n                    currOffset += 16 * chunkCount;\n                }\n                else {\n                    const chunkCount = bytes.readInt32LE(currOffset);\n                    currOffset += 4;\n                    const chunks = new Array(chunkCount);\n                    for (let k = 0; k < chunkCount; k += 1) {\n                        const u = (0, virtualOffset_1.fromBytes)(bytes, currOffset);\n                        const v = (0, virtualOffset_1.fromBytes)(bytes, currOffset + 8);\n                        currOffset += 16;\n                        firstDataLine = this._findFirstData(firstDataLine, u);\n                        chunks[k] = new chunk_1.default(u, v, bin);\n                    }\n                    binIndex[bin] = chunks;\n                }\n            }\n            // the linear index\n            const linearCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const linearIndex = new Array(linearCount);\n            for (let k = 0; k < linearCount; k += 1) {\n                linearIndex[k] = (0, virtualOffset_1.fromBytes)(bytes, currOffset);\n                currOffset += 8;\n                firstDataLine = this._findFirstData(firstDataLine, linearIndex[k]);\n            }\n            return { binIndex, linearIndex, stats };\n        });\n        return {\n            indices,\n            metaChar,\n            maxBinNumber,\n            maxRefLength,\n            skipLines,\n            firstDataLine,\n            columnNumbers,\n            coordinateType,\n            format,\n            refIdToName,\n            refNameToId,\n            maxBlockSize: 1 << 16,\n        };\n    }\n    parsePseudoBin(bytes, offset) {\n        const lineCount = (0, util_1.longToNumber)(long_1.default.fromBytesLE(bytes.slice(offset + 16, offset + 24), true));\n        return { lineCount };\n    }\n    _parseNameBytes(namesBytes) {\n        let currRefId = 0;\n        let currNameStart = 0;\n        const refIdToName = [];\n        const refNameToId = {};\n        for (let i = 0; i < namesBytes.length; i += 1) {\n            if (!namesBytes[i]) {\n                if (currNameStart < i) {\n                    let refName = namesBytes.toString('utf8', currNameStart, i);\n                    refName = this.renameRefSeq(refName);\n                    refIdToName[currRefId] = refName;\n                    refNameToId[refName] = currRefId;\n                }\n                currNameStart = i + 1;\n                currRefId += 1;\n            }\n        }\n        return { refNameToId, refIdToName };\n    }\n    async blocksForRange(refName, min, max, opts = {}) {\n        if (min < 0) {\n            min = 0;\n        }\n        const indexData = await this.parse(opts);\n        if (!indexData) {\n            return [];\n        }\n        const refId = indexData.refNameToId[refName];\n        const ba = indexData.indices[refId];\n        if (!ba) {\n            return [];\n        }\n        const minOffset = ba.linearIndex.length\n            ? ba.linearIndex[min >> TAD_LIDX_SHIFT >= ba.linearIndex.length\n                ? ba.linearIndex.length - 1\n                : min >> TAD_LIDX_SHIFT]\n            : new virtualOffset_1.default(0, 0);\n        if (!minOffset) {\n            console.warn('querying outside of possible tabix range');\n        }\n        // const { linearIndex, binIndex } = indexes\n        const overlappingBins = reg2bins(min, max); // List of bin #s that overlap min, max\n        const chunks = [];\n        // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n        for (const [start, end] of overlappingBins) {\n            for (let bin = start; bin <= end; bin++) {\n                if (ba.binIndex[bin]) {\n                    const binChunks = ba.binIndex[bin];\n                    for (let c = 0; c < binChunks.length; ++c) {\n                        chunks.push(new chunk_1.default(binChunks[c].minv, binChunks[c].maxv, bin));\n                    }\n                }\n            }\n        }\n        // Use the linear index to find minimum file position of chunks that could\n        // contain alignments in the region\n        const nintv = ba.linearIndex.length;\n        let lowest = null;\n        const minLin = Math.min(min >> 14, nintv - 1);\n        const maxLin = Math.min(max >> 14, nintv - 1);\n        for (let i = minLin; i <= maxLin; ++i) {\n            const vp = ba.linearIndex[i];\n            if (vp) {\n                if (!lowest || vp.compareTo(lowest) < 0) {\n                    lowest = vp;\n                }\n            }\n        }\n        return (0, util_1.optimizeChunks)(chunks, lowest);\n    }\n}\nexports.default = TabixIndex;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.optimizeChunks = exports.canMergeBlocks = exports.abortBreakPoint = exports.checkAbortSignal = exports.longToNumber = void 0;\nfunction longToNumber(long) {\n    if (long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n        long.lessThan(Number.MIN_SAFE_INTEGER)) {\n        throw new Error('integer overflow');\n    }\n    return long.toNumber();\n}\nexports.longToNumber = longToNumber;\nclass AbortError extends Error {\n}\n/**\n * Properly check if the given AbortSignal is aborted.\n * Per the standard, if the signal reads as aborted,\n * this function throws either a DOMException AbortError, or a regular error\n * with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nfunction checkAbortSignal(signal) {\n    if (!signal) {\n        return;\n    }\n    if (signal.aborted) {\n        // console.log('bam aborted!')\n        if (typeof DOMException !== 'undefined') {\n            // eslint-disable-next-line  no-undef\n            throw new DOMException('aborted', 'AbortError');\n        }\n        else {\n            const e = new AbortError('aborted');\n            e.code = 'ERR_ABORTED';\n            throw e;\n        }\n    }\n}\nexports.checkAbortSignal = checkAbortSignal;\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nasync function abortBreakPoint(signal) {\n    await Promise.resolve();\n    checkAbortSignal(signal);\n}\nexports.abortBreakPoint = abortBreakPoint;\nfunction canMergeBlocks(chunk1, chunk2) {\n    return (chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n        chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000);\n}\nexports.canMergeBlocks = canMergeBlocks;\nfunction optimizeChunks(chunks, lowest) {\n    const mergedChunks = [];\n    let lastChunk = null;\n    if (chunks.length === 0) {\n        return chunks;\n    }\n    chunks.sort(function (c0, c1) {\n        const dif = c0.minv.blockPosition - c1.minv.blockPosition;\n        if (dif !== 0) {\n            return dif;\n        }\n        else {\n            return c0.minv.dataPosition - c1.minv.dataPosition;\n        }\n    });\n    chunks.forEach(chunk => {\n        if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n            if (lastChunk === null) {\n                mergedChunks.push(chunk);\n                lastChunk = chunk;\n            }\n            else {\n                if (canMergeBlocks(lastChunk, chunk)) {\n                    if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n                        lastChunk.maxv = chunk.maxv;\n                    }\n                }\n                else {\n                    mergedChunks.push(chunk);\n                    lastChunk = chunk;\n                }\n            }\n        }\n        // else {\n        //   console.log(`skipping chunk ${chunk}`)\n        // }\n    });\n    return mergedChunks;\n}\nexports.optimizeChunks = optimizeChunks;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fromBytes = void 0;\nclass VirtualOffset {\n    constructor(blockPosition, dataPosition) {\n        this.blockPosition = blockPosition; // < offset of the compressed data block\n        this.dataPosition = dataPosition; // < offset into the uncompressed data\n    }\n    toString() {\n        return `${this.blockPosition}:${this.dataPosition}`;\n    }\n    compareTo(b) {\n        return (this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition);\n    }\n    static min(...args) {\n        let min;\n        let i = 0;\n        for (; !min; i += 1) {\n            min = args[i];\n        }\n        for (; i < args.length; i += 1) {\n            if (min.compareTo(args[i]) > 0) {\n                min = args[i];\n            }\n        }\n        return min;\n    }\n}\nexports.default = VirtualOffset;\nfunction fromBytes(bytes, offset = 0, bigendian = false) {\n    if (bigendian) {\n        throw new Error('big-endian virtual file offsets not implemented');\n    }\n    return new VirtualOffset(bytes[offset + 7] * 0x10000000000 +\n        bytes[offset + 6] * 0x100000000 +\n        bytes[offset + 5] * 0x1000000 +\n        bytes[offset + 4] * 0x10000 +\n        bytes[offset + 3] * 0x100 +\n        bytes[offset + 2], (bytes[offset + 1] << 8) | bytes[offset]);\n}\nexports.fromBytes = fromBytes;\n"],"names":["objectWithoutPropertiesLoose","module","exports","source","excluded","key","i","target","Object","getOwnPropertySymbols","sourceSymbolKeys","length","indexOf","prototype","propertyIsEnumerable","call","__esModule","sourceKeys","keys","defineProperty","value","Chunk","minv","maxv","bin","fetchedSize","undefined","this","_fetchedSize","toUniqueString","b","compareTo","blockPosition","__createBinding","create","o","m","k","k2","enumerable","get","__setModuleDefault","v","__importStar","mod","result","hasOwnProperty","__importDefault","long_1","require","bgzf_filehandle_1","virtualOffset_1","chunk_1","util_1","indexFile_1","CSI1_MAGIC","CSI2_MAGIC","rshift","num","bits","Math","floor","CSI","args","maxBinNumber","depth","minShift","refName","opts","parse","indexData","refId","refNameToId","indices","stats","lineCount","Error","bytes","offset","auxLength","refIdToName","formatFlags","readInt32LE","coordinateType","format","columnNumbers","ref","start","end","metaValue","metaChar","String","fromCharCode","skipLines","nameSectionLength","_parseNameBytes","slice","namesBytes","currRefId","currNameStart","toString","renameRefSeq","unzip","filehandle","readFile","readUInt32LE","csiVersion","maxRefLength","aux","parseAuxData","refCount","currOffset","Array","fill","map","binCount","binIndex","j","parsePseudoBin","loffset","fromBytes","firstDataLine","_findFirstData","chunkCount","chunks","u","default","csi","maxBlockSize","longToNumber","fromBytesLE","min","max","ba","overlappingBins","reg2bins","binChunks","c","push","optimizeChunks","beg","l","t","s","bins","e","TBI","TabixIndexedFile","tabixIndexedFile_1","tbi_1","csi_1","abortable_promise_cache_1","quick_lru_1","IndexFile","renameRefSeqs","n","rest","currentFdl","virtualOffset","_parseCache","cache","maxSize","_parse","seqId","generic_filehandle_1","timeout","time","Promise","resolve","setTimeout","path","tbiPath","tbiFilehandle","csiPath","csiFilehandle","chunkSizeLimit","chunkCacheSize","TypeError","LocalFile","index","chunkCache","readChunk","bind","options","callback","lineCallback","getMetadata","metadata","checkAbortSignal","signal","blocksForRange","size","toLocaleString","last","Date","now","chunkNum","previousStartCoordinate","buffer","cpositions","dpositions","lines","TextDecoder","decode","split","pop","blockStart","dataPosition","pos","line","checkLine","startCoordinate","overlaps","trim","maxFetch","_readRegion","console","error","code","lastNewline","newlineByte","charCodeAt","metaByte","getHeaderBuffer","regionRefName","regionStart","regionEnd","charAt","maxColumn","currentColumnNumber","currentColumnStart","refSeq","Infinity","parseInt","_getVcfEnd","info","endCoordinate","isTRA","prevChar","valueEnd","position","compressedSize","read","Buffer","alloc","bytesRead","chunk","compressedData","unzipChunkSlice","TBI_MAGIC","TabixIndex","linearCount","linearIndex","warn","nintv","lowest","minLin","maxLin","vp","canMergeBlocks","abortBreakPoint","long","greaterThan","Number","MAX_SAFE_INTEGER","lessThan","MIN_SAFE_INTEGER","toNumber","AbortError","aborted","DOMException","chunk1","chunk2","mergedChunks","lastChunk","sort","c0","c1","dif","forEach","VirtualOffset","bigendian"],"sourceRoot":""}